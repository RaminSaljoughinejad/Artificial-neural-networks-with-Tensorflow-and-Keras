{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Fisherman Problem\n",
    "<span style=\"color:red;\">Aim:</span><br>\n",
    "Understaning of Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a List of our data(fish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_fishes = [\n",
    "                [1.0,4.0,0],[4.0,6.0,0],[1.0,6.0,0],[7.0,7.0,0],[7.5,8.0,0],[3.0,8.0,0],[8.0,8.0,0],\n",
    "                [10.0,11.0,0],[8.5,7.0,0],[4.0,9.0,0],[1.0,10.0,0],[2.0,11.0,0],[2.0,11.0,0],\n",
    "                [2.0,1.0,1],[4.0,2.5,1],[6.0,3.0,1],[6.0,2.0,1],[7.5,3.0,1],[8.0,0.5,1],\n",
    "                [8.0,5.0,1],[10.0,2.0,1],[10.0,4.0,1],[11.0,3.0,1],[12.0,2.0,1],[13.0,7.0,1],\n",
    "                [12.0,3.0,1]\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.axis([0, 20, 0, 20])\n",
    "for fish in All_fishes:\n",
    "    if fish[2]==0:\n",
    "        plt.plot(fish[0], fish[1], 'ro', color=\"red\")\n",
    "    else:\n",
    "        plt.plot(fish[0], fish[1], 'ro', color=\"blue\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_fises= np.asarray(All_fishes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(All_fishes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.0, 9.0, 0], [11.0, 3.0, 1], [10.0, 2.0, 1], [4.0, 2.5, 1], [3.0, 8.0, 0], [7.0, 7.0, 0], [8.0, 8.0, 0], [6.0, 2.0, 1], [10.0, 11.0, 0], [4.0, 6.0, 0], [2.0, 11.0, 0], [2.0, 11.0, 0], [13.0, 7.0, 1], [8.0, 0.5, 1], [8.5, 7.0, 0], [1.0, 6.0, 0], [6.0, 3.0, 1], [12.0, 2.0, 1], [1.0, 10.0, 0], [10.0, 4.0, 1], [2.0, 1.0, 1], [7.5, 8.0, 0], [12.0, 3.0, 1], [8.0, 5.0, 1], [1.0, 4.0, 0], [7.5, 3.0, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(All_fishes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input = []\n",
    "labels = []\n",
    "for fish in All_fishes:\n",
    "    X_input.append([fish[0],fish[1]])\n",
    "    labels.append(fish[2])\n",
    "X_input = np.asarray(X_input)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "labels = keras.utils.to_categorical(labels, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, activation=\"sigmoid\", input_shape=(2,)))\n",
    "model.add(Dense(2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",optimizer=SGD(lr=0.03), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23 samples, validate on 3 samples\n",
      "Epoch 1/500\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.9075 - acc: 0.4783 - val_loss: 0.6204 - val_acc: 0.6667\n",
      "Epoch 2/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.8914 - acc: 0.4783 - val_loss: 0.6158 - val_acc: 0.6667\n",
      "Epoch 3/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.8763 - acc: 0.4783 - val_loss: 0.6119 - val_acc: 0.6667\n",
      "Epoch 4/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.8622 - acc: 0.4783 - val_loss: 0.6086 - val_acc: 0.6667\n",
      "Epoch 5/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.8490 - acc: 0.4783 - val_loss: 0.6058 - val_acc: 0.6667\n",
      "Epoch 6/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.8366 - acc: 0.4783 - val_loss: 0.6036 - val_acc: 0.6667\n",
      "Epoch 7/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.8251 - acc: 0.4783 - val_loss: 0.6018 - val_acc: 0.6667\n",
      "Epoch 8/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.8144 - acc: 0.4783 - val_loss: 0.6004 - val_acc: 0.6667\n",
      "Epoch 9/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.8044 - acc: 0.4783 - val_loss: 0.5994 - val_acc: 0.6667\n",
      "Epoch 10/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.7952 - acc: 0.4783 - val_loss: 0.5988 - val_acc: 0.6667\n",
      "Epoch 11/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.7866 - acc: 0.4783 - val_loss: 0.5986 - val_acc: 0.6667\n",
      "Epoch 12/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.7787 - acc: 0.4783 - val_loss: 0.5986 - val_acc: 0.6667\n",
      "Epoch 13/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.7714 - acc: 0.4783 - val_loss: 0.5989 - val_acc: 0.6667\n",
      "Epoch 14/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.7646 - acc: 0.4783 - val_loss: 0.5995 - val_acc: 0.6667\n",
      "Epoch 15/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.7583 - acc: 0.4783 - val_loss: 0.6002 - val_acc: 0.6667\n",
      "Epoch 16/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.7525 - acc: 0.4783 - val_loss: 0.6011 - val_acc: 0.6667\n",
      "Epoch 17/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.7472 - acc: 0.4783 - val_loss: 0.6022 - val_acc: 0.6667\n",
      "Epoch 18/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.7423 - acc: 0.4783 - val_loss: 0.6035 - val_acc: 0.6667\n",
      "Epoch 19/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.7378 - acc: 0.4783 - val_loss: 0.6049 - val_acc: 0.6667\n",
      "Epoch 20/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.7336 - acc: 0.4783 - val_loss: 0.6063 - val_acc: 0.6667\n",
      "Epoch 21/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.7298 - acc: 0.4783 - val_loss: 0.6079 - val_acc: 0.6667\n",
      "Epoch 22/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.7263 - acc: 0.4783 - val_loss: 0.6095 - val_acc: 0.6667\n",
      "Epoch 23/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.7231 - acc: 0.4783 - val_loss: 0.6111 - val_acc: 0.6667\n",
      "Epoch 24/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.7201 - acc: 0.4783 - val_loss: 0.6128 - val_acc: 0.6667\n",
      "Epoch 25/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.7173 - acc: 0.4783 - val_loss: 0.6146 - val_acc: 0.6667\n",
      "Epoch 26/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.7148 - acc: 0.4783 - val_loss: 0.6163 - val_acc: 0.6667\n",
      "Epoch 27/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.7125 - acc: 0.4783 - val_loss: 0.6181 - val_acc: 0.6667\n",
      "Epoch 28/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.7104 - acc: 0.4783 - val_loss: 0.6198 - val_acc: 0.6667\n",
      "Epoch 29/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.7085 - acc: 0.4783 - val_loss: 0.6216 - val_acc: 0.6667\n",
      "Epoch 30/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.7067 - acc: 0.4783 - val_loss: 0.6233 - val_acc: 0.6667\n",
      "Epoch 31/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.7050 - acc: 0.4783 - val_loss: 0.6251 - val_acc: 0.6667\n",
      "Epoch 32/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.7035 - acc: 0.4783 - val_loss: 0.6268 - val_acc: 0.6667\n",
      "Epoch 33/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.7021 - acc: 0.4783 - val_loss: 0.6284 - val_acc: 0.6667\n",
      "Epoch 34/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.7009 - acc: 0.4783 - val_loss: 0.6300 - val_acc: 0.6667\n",
      "Epoch 35/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6997 - acc: 0.4783 - val_loss: 0.6316 - val_acc: 0.6667\n",
      "Epoch 36/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6986 - acc: 0.4783 - val_loss: 0.6332 - val_acc: 0.6667\n",
      "Epoch 37/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.6976 - acc: 0.4783 - val_loss: 0.6347 - val_acc: 0.6667\n",
      "Epoch 38/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6967 - acc: 0.4783 - val_loss: 0.6362 - val_acc: 1.0000\n",
      "Epoch 39/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6958 - acc: 0.4783 - val_loss: 0.6376 - val_acc: 1.0000\n",
      "Epoch 40/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6950 - acc: 0.4783 - val_loss: 0.6390 - val_acc: 1.0000\n",
      "Epoch 41/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6943 - acc: 0.4783 - val_loss: 0.6404 - val_acc: 1.0000\n",
      "Epoch 42/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6936 - acc: 0.5217 - val_loss: 0.6416 - val_acc: 1.0000\n",
      "Epoch 43/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6930 - acc: 0.5217 - val_loss: 0.6429 - val_acc: 1.0000\n",
      "Epoch 44/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6924 - acc: 0.4783 - val_loss: 0.6441 - val_acc: 1.0000\n",
      "Epoch 45/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6918 - acc: 0.4783 - val_loss: 0.6452 - val_acc: 1.0000\n",
      "Epoch 46/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6913 - acc: 0.4783 - val_loss: 0.6464 - val_acc: 1.0000\n",
      "Epoch 47/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6908 - acc: 0.4783 - val_loss: 0.6474 - val_acc: 1.0000\n",
      "Epoch 48/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.6904 - acc: 0.5217 - val_loss: 0.6484 - val_acc: 1.0000\n",
      "Epoch 49/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6899 - acc: 0.5217 - val_loss: 0.6494 - val_acc: 1.0000\n",
      "Epoch 50/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6895 - acc: 0.5217 - val_loss: 0.6503 - val_acc: 1.0000\n",
      "Epoch 51/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6892 - acc: 0.5217 - val_loss: 0.6512 - val_acc: 1.0000\n",
      "Epoch 52/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6888 - acc: 0.5217 - val_loss: 0.6520 - val_acc: 1.0000\n",
      "Epoch 53/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6885 - acc: 0.5217 - val_loss: 0.6528 - val_acc: 1.0000\n",
      "Epoch 54/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.6881 - acc: 0.5217 - val_loss: 0.6536 - val_acc: 1.0000\n",
      "Epoch 55/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6878 - acc: 0.6087 - val_loss: 0.6543 - val_acc: 1.0000\n",
      "Epoch 56/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6875 - acc: 0.6087 - val_loss: 0.6549 - val_acc: 1.0000\n",
      "Epoch 57/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6872 - acc: 0.6522 - val_loss: 0.6556 - val_acc: 1.0000\n",
      "Epoch 58/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6869 - acc: 0.6087 - val_loss: 0.6561 - val_acc: 1.0000\n",
      "Epoch 59/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.6866 - acc: 0.6087 - val_loss: 0.6567 - val_acc: 1.0000\n",
      "Epoch 60/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6864 - acc: 0.6522 - val_loss: 0.6572 - val_acc: 1.0000\n",
      "Epoch 61/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6861 - acc: 0.6957 - val_loss: 0.6577 - val_acc: 1.0000\n",
      "Epoch 62/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6858 - acc: 0.6957 - val_loss: 0.6581 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6856 - acc: 0.6957 - val_loss: 0.6585 - val_acc: 1.0000\n",
      "Epoch 64/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6853 - acc: 0.6522 - val_loss: 0.6589 - val_acc: 1.0000\n",
      "Epoch 65/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6850 - acc: 0.6087 - val_loss: 0.6592 - val_acc: 0.3333\n",
      "Epoch 66/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.6848 - acc: 0.7826 - val_loss: 0.6595 - val_acc: 0.3333\n",
      "Epoch 67/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6845 - acc: 0.5652 - val_loss: 0.6597 - val_acc: 0.3333\n",
      "Epoch 68/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6842 - acc: 0.5217 - val_loss: 0.6600 - val_acc: 0.3333\n",
      "Epoch 69/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6840 - acc: 0.5217 - val_loss: 0.6602 - val_acc: 0.3333\n",
      "Epoch 70/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6837 - acc: 0.5217 - val_loss: 0.6603 - val_acc: 0.3333\n",
      "Epoch 71/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6834 - acc: 0.5217 - val_loss: 0.6605 - val_acc: 0.3333\n",
      "Epoch 72/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.6831 - acc: 0.5217 - val_loss: 0.6606 - val_acc: 0.3333\n",
      "Epoch 73/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6828 - acc: 0.5217 - val_loss: 0.6607 - val_acc: 0.3333\n",
      "Epoch 74/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6825 - acc: 0.5217 - val_loss: 0.6607 - val_acc: 0.3333\n",
      "Epoch 75/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6822 - acc: 0.5217 - val_loss: 0.6607 - val_acc: 0.3333\n",
      "Epoch 76/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6819 - acc: 0.5217 - val_loss: 0.6607 - val_acc: 0.3333\n",
      "Epoch 77/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6816 - acc: 0.5217 - val_loss: 0.6607 - val_acc: 0.3333\n",
      "Epoch 78/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6813 - acc: 0.5217 - val_loss: 0.6606 - val_acc: 0.3333\n",
      "Epoch 79/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6809 - acc: 0.5217 - val_loss: 0.6605 - val_acc: 0.3333\n",
      "Epoch 80/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6806 - acc: 0.5217 - val_loss: 0.6603 - val_acc: 0.3333\n",
      "Epoch 81/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6802 - acc: 0.5217 - val_loss: 0.6602 - val_acc: 0.3333\n",
      "Epoch 82/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6798 - acc: 0.5217 - val_loss: 0.6600 - val_acc: 0.3333\n",
      "Epoch 83/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6794 - acc: 0.5217 - val_loss: 0.6598 - val_acc: 0.3333\n",
      "Epoch 84/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6790 - acc: 0.5217 - val_loss: 0.6595 - val_acc: 0.3333\n",
      "Epoch 85/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.6785 - acc: 0.5217 - val_loss: 0.6593 - val_acc: 0.3333\n",
      "Epoch 86/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6781 - acc: 0.5217 - val_loss: 0.6590 - val_acc: 0.3333\n",
      "Epoch 87/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6776 - acc: 0.5217 - val_loss: 0.6586 - val_acc: 0.3333\n",
      "Epoch 88/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6771 - acc: 0.5217 - val_loss: 0.6583 - val_acc: 0.3333\n",
      "Epoch 89/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6766 - acc: 0.5217 - val_loss: 0.6579 - val_acc: 0.3333\n",
      "Epoch 90/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6761 - acc: 0.5217 - val_loss: 0.6574 - val_acc: 0.3333\n",
      "Epoch 91/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6755 - acc: 0.5217 - val_loss: 0.6570 - val_acc: 0.3333\n",
      "Epoch 92/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6749 - acc: 0.5217 - val_loss: 0.6565 - val_acc: 0.3333\n",
      "Epoch 93/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6743 - acc: 0.5217 - val_loss: 0.6560 - val_acc: 0.3333\n",
      "Epoch 94/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6736 - acc: 0.5217 - val_loss: 0.6554 - val_acc: 0.3333\n",
      "Epoch 95/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6730 - acc: 0.5217 - val_loss: 0.6549 - val_acc: 0.3333\n",
      "Epoch 96/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6722 - acc: 0.5217 - val_loss: 0.6542 - val_acc: 0.3333\n",
      "Epoch 97/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6715 - acc: 0.5217 - val_loss: 0.6536 - val_acc: 0.3333\n",
      "Epoch 98/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.6707 - acc: 0.5217 - val_loss: 0.6529 - val_acc: 0.3333\n",
      "Epoch 99/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6699 - acc: 0.5217 - val_loss: 0.6522 - val_acc: 0.3333\n",
      "Epoch 100/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6690 - acc: 0.5217 - val_loss: 0.6514 - val_acc: 0.3333\n",
      "Epoch 101/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6681 - acc: 0.5217 - val_loss: 0.6506 - val_acc: 0.3333\n",
      "Epoch 102/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6672 - acc: 0.5217 - val_loss: 0.6498 - val_acc: 0.3333\n",
      "Epoch 103/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6662 - acc: 0.5217 - val_loss: 0.6489 - val_acc: 0.3333\n",
      "Epoch 104/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6652 - acc: 0.5217 - val_loss: 0.6480 - val_acc: 0.3333\n",
      "Epoch 105/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6641 - acc: 0.5217 - val_loss: 0.6471 - val_acc: 0.3333\n",
      "Epoch 106/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6630 - acc: 0.5217 - val_loss: 0.6461 - val_acc: 0.3333\n",
      "Epoch 107/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6618 - acc: 0.5217 - val_loss: 0.6451 - val_acc: 0.3333\n",
      "Epoch 108/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6606 - acc: 0.5217 - val_loss: 0.6440 - val_acc: 0.3333\n",
      "Epoch 109/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6593 - acc: 0.5217 - val_loss: 0.6429 - val_acc: 0.3333\n",
      "Epoch 110/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6580 - acc: 0.5217 - val_loss: 0.6418 - val_acc: 0.3333\n",
      "Epoch 111/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.6567 - acc: 0.5217 - val_loss: 0.6406 - val_acc: 0.3333\n",
      "Epoch 112/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6553 - acc: 0.5217 - val_loss: 0.6394 - val_acc: 0.3333\n",
      "Epoch 113/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6539 - acc: 0.5217 - val_loss: 0.6382 - val_acc: 0.3333\n",
      "Epoch 114/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6524 - acc: 0.5217 - val_loss: 0.6369 - val_acc: 0.3333\n",
      "Epoch 115/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6509 - acc: 0.5217 - val_loss: 0.6356 - val_acc: 0.3333\n",
      "Epoch 116/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6494 - acc: 0.5217 - val_loss: 0.6343 - val_acc: 0.3333\n",
      "Epoch 117/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.6478 - acc: 0.5217 - val_loss: 0.6329 - val_acc: 0.3333\n",
      "Epoch 118/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6462 - acc: 0.5217 - val_loss: 0.6315 - val_acc: 0.3333\n",
      "Epoch 119/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6446 - acc: 0.5217 - val_loss: 0.6301 - val_acc: 0.3333\n",
      "Epoch 120/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6430 - acc: 0.5217 - val_loss: 0.6287 - val_acc: 0.3333\n",
      "Epoch 121/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6413 - acc: 0.5217 - val_loss: 0.6272 - val_acc: 0.3333\n",
      "Epoch 122/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.6397 - acc: 0.5217 - val_loss: 0.6257 - val_acc: 0.3333\n",
      "Epoch 123/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6380 - acc: 0.5217 - val_loss: 0.6242 - val_acc: 0.3333\n",
      "Epoch 124/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6363 - acc: 0.5217 - val_loss: 0.6227 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6346 - acc: 0.7826 - val_loss: 0.6212 - val_acc: 0.3333\n",
      "Epoch 126/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6330 - acc: 0.8261 - val_loss: 0.6196 - val_acc: 0.3333\n",
      "Epoch 127/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.6313 - acc: 0.8261 - val_loss: 0.6180 - val_acc: 0.3333\n",
      "Epoch 128/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6296 - acc: 0.8261 - val_loss: 0.6165 - val_acc: 0.6667\n",
      "Epoch 129/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6279 - acc: 0.7826 - val_loss: 0.6149 - val_acc: 1.0000\n",
      "Epoch 130/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6262 - acc: 0.7391 - val_loss: 0.6133 - val_acc: 1.0000\n",
      "Epoch 131/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6246 - acc: 0.7391 - val_loss: 0.6117 - val_acc: 1.0000\n",
      "Epoch 132/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6229 - acc: 0.7391 - val_loss: 0.6101 - val_acc: 1.0000\n",
      "Epoch 133/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6212 - acc: 0.7391 - val_loss: 0.6085 - val_acc: 1.0000\n",
      "Epoch 134/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6196 - acc: 0.7826 - val_loss: 0.6069 - val_acc: 1.0000\n",
      "Epoch 135/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6179 - acc: 0.7826 - val_loss: 0.6053 - val_acc: 1.0000\n",
      "Epoch 136/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6163 - acc: 0.7826 - val_loss: 0.6037 - val_acc: 1.0000\n",
      "Epoch 137/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.6146 - acc: 0.7826 - val_loss: 0.6022 - val_acc: 1.0000\n",
      "Epoch 138/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6130 - acc: 0.7826 - val_loss: 0.6006 - val_acc: 1.0000\n",
      "Epoch 139/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6113 - acc: 0.8261 - val_loss: 0.5990 - val_acc: 1.0000\n",
      "Epoch 140/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6097 - acc: 0.8261 - val_loss: 0.5974 - val_acc: 1.0000\n",
      "Epoch 141/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6080 - acc: 0.7826 - val_loss: 0.5958 - val_acc: 1.0000\n",
      "Epoch 142/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.6064 - acc: 0.7826 - val_loss: 0.5943 - val_acc: 1.0000\n",
      "Epoch 143/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6047 - acc: 0.7826 - val_loss: 0.5927 - val_acc: 1.0000\n",
      "Epoch 144/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6031 - acc: 0.7826 - val_loss: 0.5912 - val_acc: 1.0000\n",
      "Epoch 145/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.6014 - acc: 0.8261 - val_loss: 0.5896 - val_acc: 1.0000\n",
      "Epoch 146/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5997 - acc: 0.8261 - val_loss: 0.5881 - val_acc: 1.0000\n",
      "Epoch 147/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5980 - acc: 0.8261 - val_loss: 0.5866 - val_acc: 1.0000\n",
      "Epoch 148/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5963 - acc: 0.8261 - val_loss: 0.5851 - val_acc: 1.0000\n",
      "Epoch 149/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5945 - acc: 0.8261 - val_loss: 0.5836 - val_acc: 1.0000\n",
      "Epoch 150/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5928 - acc: 0.8261 - val_loss: 0.5822 - val_acc: 1.0000\n",
      "Epoch 151/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5910 - acc: 0.8261 - val_loss: 0.5807 - val_acc: 1.0000\n",
      "Epoch 152/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5891 - acc: 0.8261 - val_loss: 0.5793 - val_acc: 1.0000\n",
      "Epoch 153/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.5872 - acc: 0.8261 - val_loss: 0.5779 - val_acc: 1.0000\n",
      "Epoch 154/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5853 - acc: 0.8261 - val_loss: 0.5765 - val_acc: 1.0000\n",
      "Epoch 155/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5833 - acc: 0.8696 - val_loss: 0.5752 - val_acc: 1.0000\n",
      "Epoch 156/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5813 - acc: 0.8696 - val_loss: 0.5739 - val_acc: 1.0000\n",
      "Epoch 157/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5792 - acc: 0.8696 - val_loss: 0.5726 - val_acc: 1.0000\n",
      "Epoch 158/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.5771 - acc: 0.8696 - val_loss: 0.5714 - val_acc: 1.0000\n",
      "Epoch 159/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5749 - acc: 0.8696 - val_loss: 0.5702 - val_acc: 1.0000\n",
      "Epoch 160/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5725 - acc: 0.8696 - val_loss: 0.5690 - val_acc: 1.0000\n",
      "Epoch 161/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5702 - acc: 0.8696 - val_loss: 0.5679 - val_acc: 1.0000\n",
      "Epoch 162/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5677 - acc: 0.8696 - val_loss: 0.5669 - val_acc: 1.0000\n",
      "Epoch 163/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5651 - acc: 0.8696 - val_loss: 0.5660 - val_acc: 1.0000\n",
      "Epoch 164/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5624 - acc: 0.8696 - val_loss: 0.5651 - val_acc: 1.0000\n",
      "Epoch 165/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5596 - acc: 0.8696 - val_loss: 0.5643 - val_acc: 1.0000\n",
      "Epoch 166/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5568 - acc: 0.8696 - val_loss: 0.5636 - val_acc: 1.0000\n",
      "Epoch 167/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5538 - acc: 0.9130 - val_loss: 0.5630 - val_acc: 1.0000\n",
      "Epoch 168/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5508 - acc: 0.9130 - val_loss: 0.5624 - val_acc: 1.0000\n",
      "Epoch 169/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5477 - acc: 0.9130 - val_loss: 0.5620 - val_acc: 1.0000\n",
      "Epoch 170/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5445 - acc: 0.9130 - val_loss: 0.5617 - val_acc: 1.0000\n",
      "Epoch 171/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5413 - acc: 0.9130 - val_loss: 0.5615 - val_acc: 1.0000\n",
      "Epoch 172/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5381 - acc: 0.9130 - val_loss: 0.5613 - val_acc: 1.0000\n",
      "Epoch 173/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5349 - acc: 0.9130 - val_loss: 0.5613 - val_acc: 1.0000\n",
      "Epoch 174/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.5318 - acc: 0.9130 - val_loss: 0.5613 - val_acc: 1.0000\n",
      "Epoch 175/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5287 - acc: 0.9130 - val_loss: 0.5614 - val_acc: 1.0000\n",
      "Epoch 176/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5258 - acc: 0.9130 - val_loss: 0.5615 - val_acc: 1.0000\n",
      "Epoch 177/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5229 - acc: 0.9130 - val_loss: 0.5616 - val_acc: 1.0000\n",
      "Epoch 178/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5201 - acc: 0.9130 - val_loss: 0.5617 - val_acc: 1.0000\n",
      "Epoch 179/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.5174 - acc: 0.9130 - val_loss: 0.5618 - val_acc: 1.0000\n",
      "Epoch 180/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5149 - acc: 0.9130 - val_loss: 0.5619 - val_acc: 1.0000\n",
      "Epoch 181/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5124 - acc: 0.9130 - val_loss: 0.5619 - val_acc: 1.0000\n",
      "Epoch 182/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5101 - acc: 0.9130 - val_loss: 0.5619 - val_acc: 1.0000\n",
      "Epoch 183/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5079 - acc: 0.9130 - val_loss: 0.5618 - val_acc: 1.0000\n",
      "Epoch 184/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5058 - acc: 0.9130 - val_loss: 0.5617 - val_acc: 0.6667\n",
      "Epoch 185/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5038 - acc: 0.9130 - val_loss: 0.5615 - val_acc: 0.6667\n",
      "Epoch 186/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5018 - acc: 0.9130 - val_loss: 0.5612 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.5000 - acc: 0.9130 - val_loss: 0.5609 - val_acc: 0.6667\n",
      "Epoch 188/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4982 - acc: 0.9130 - val_loss: 0.5604 - val_acc: 0.6667\n",
      "Epoch 189/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4965 - acc: 0.9130 - val_loss: 0.5599 - val_acc: 0.6667\n",
      "Epoch 190/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4948 - acc: 0.9130 - val_loss: 0.5594 - val_acc: 0.6667\n",
      "Epoch 191/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4932 - acc: 0.9130 - val_loss: 0.5587 - val_acc: 0.6667\n",
      "Epoch 192/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4916 - acc: 0.9130 - val_loss: 0.5580 - val_acc: 0.6667\n",
      "Epoch 193/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4901 - acc: 0.9130 - val_loss: 0.5572 - val_acc: 0.6667\n",
      "Epoch 194/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4886 - acc: 0.9130 - val_loss: 0.5564 - val_acc: 0.6667\n",
      "Epoch 195/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4871 - acc: 0.9130 - val_loss: 0.5555 - val_acc: 0.6667\n",
      "Epoch 196/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4857 - acc: 0.9130 - val_loss: 0.5546 - val_acc: 0.6667\n",
      "Epoch 197/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4843 - acc: 0.9130 - val_loss: 0.5536 - val_acc: 0.6667\n",
      "Epoch 198/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4829 - acc: 0.9130 - val_loss: 0.5526 - val_acc: 0.6667\n",
      "Epoch 199/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4815 - acc: 0.9130 - val_loss: 0.5516 - val_acc: 0.6667\n",
      "Epoch 200/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4802 - acc: 0.9130 - val_loss: 0.5505 - val_acc: 0.6667\n",
      "Epoch 201/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4788 - acc: 0.9130 - val_loss: 0.5494 - val_acc: 0.6667\n",
      "Epoch 202/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4775 - acc: 0.9130 - val_loss: 0.5482 - val_acc: 1.0000\n",
      "Epoch 203/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4762 - acc: 0.9130 - val_loss: 0.5471 - val_acc: 1.0000\n",
      "Epoch 204/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.4750 - acc: 0.9130 - val_loss: 0.5459 - val_acc: 1.0000\n",
      "Epoch 205/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4737 - acc: 0.9130 - val_loss: 0.5447 - val_acc: 1.0000\n",
      "Epoch 206/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4724 - acc: 0.9130 - val_loss: 0.5435 - val_acc: 1.0000\n",
      "Epoch 207/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4712 - acc: 0.9130 - val_loss: 0.5423 - val_acc: 1.0000\n",
      "Epoch 208/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4700 - acc: 0.9130 - val_loss: 0.5410 - val_acc: 1.0000\n",
      "Epoch 209/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.4687 - acc: 0.9130 - val_loss: 0.5398 - val_acc: 1.0000\n",
      "Epoch 210/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4675 - acc: 0.9130 - val_loss: 0.5385 - val_acc: 1.0000\n",
      "Epoch 211/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4663 - acc: 0.9130 - val_loss: 0.5372 - val_acc: 1.0000\n",
      "Epoch 212/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4651 - acc: 0.9130 - val_loss: 0.5360 - val_acc: 1.0000\n",
      "Epoch 213/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4639 - acc: 0.9130 - val_loss: 0.5347 - val_acc: 1.0000\n",
      "Epoch 214/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4627 - acc: 0.9130 - val_loss: 0.5334 - val_acc: 1.0000\n",
      "Epoch 215/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4616 - acc: 0.9130 - val_loss: 0.5322 - val_acc: 1.0000\n",
      "Epoch 216/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4604 - acc: 0.9130 - val_loss: 0.5309 - val_acc: 1.0000\n",
      "Epoch 217/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4592 - acc: 0.9130 - val_loss: 0.5296 - val_acc: 1.0000\n",
      "Epoch 218/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4581 - acc: 0.9130 - val_loss: 0.5283 - val_acc: 1.0000\n",
      "Epoch 219/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4569 - acc: 0.9130 - val_loss: 0.5270 - val_acc: 1.0000\n",
      "Epoch 220/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4558 - acc: 0.9130 - val_loss: 0.5258 - val_acc: 1.0000\n",
      "Epoch 221/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4546 - acc: 0.9130 - val_loss: 0.5245 - val_acc: 1.0000\n",
      "Epoch 222/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4535 - acc: 0.9130 - val_loss: 0.5232 - val_acc: 1.0000\n",
      "Epoch 223/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4523 - acc: 0.9130 - val_loss: 0.5220 - val_acc: 1.0000\n",
      "Epoch 224/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4512 - acc: 0.9130 - val_loss: 0.5207 - val_acc: 1.0000\n",
      "Epoch 225/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4501 - acc: 0.9130 - val_loss: 0.5195 - val_acc: 1.0000\n",
      "Epoch 226/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4490 - acc: 0.9130 - val_loss: 0.5182 - val_acc: 1.0000\n",
      "Epoch 227/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4479 - acc: 0.9130 - val_loss: 0.5170 - val_acc: 1.0000\n",
      "Epoch 228/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.4468 - acc: 0.9130 - val_loss: 0.5157 - val_acc: 1.0000\n",
      "Epoch 229/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4457 - acc: 0.9130 - val_loss: 0.5145 - val_acc: 1.0000\n",
      "Epoch 230/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4446 - acc: 0.9130 - val_loss: 0.5132 - val_acc: 1.0000\n",
      "Epoch 231/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4435 - acc: 0.9130 - val_loss: 0.5120 - val_acc: 1.0000\n",
      "Epoch 232/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4424 - acc: 0.9130 - val_loss: 0.5108 - val_acc: 1.0000\n",
      "Epoch 233/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4413 - acc: 0.9130 - val_loss: 0.5096 - val_acc: 1.0000\n",
      "Epoch 234/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4402 - acc: 0.9130 - val_loss: 0.5083 - val_acc: 1.0000\n",
      "Epoch 235/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4391 - acc: 0.9130 - val_loss: 0.5071 - val_acc: 1.0000\n",
      "Epoch 236/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4380 - acc: 0.9130 - val_loss: 0.5059 - val_acc: 1.0000\n",
      "Epoch 237/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4370 - acc: 0.9130 - val_loss: 0.5047 - val_acc: 1.0000\n",
      "Epoch 238/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4359 - acc: 0.9130 - val_loss: 0.5035 - val_acc: 1.0000\n",
      "Epoch 239/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4348 - acc: 0.9130 - val_loss: 0.5023 - val_acc: 1.0000\n",
      "Epoch 240/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4338 - acc: 0.9130 - val_loss: 0.5011 - val_acc: 1.0000\n",
      "Epoch 241/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4327 - acc: 0.9130 - val_loss: 0.5000 - val_acc: 1.0000\n",
      "Epoch 242/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4316 - acc: 0.9130 - val_loss: 0.4988 - val_acc: 1.0000\n",
      "Epoch 243/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4306 - acc: 0.9130 - val_loss: 0.4976 - val_acc: 1.0000\n",
      "Epoch 244/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4295 - acc: 0.9130 - val_loss: 0.4964 - val_acc: 1.0000\n",
      "Epoch 245/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4285 - acc: 0.9130 - val_loss: 0.4953 - val_acc: 1.0000\n",
      "Epoch 246/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4275 - acc: 0.9130 - val_loss: 0.4941 - val_acc: 1.0000\n",
      "Epoch 247/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4264 - acc: 0.9130 - val_loss: 0.4929 - val_acc: 1.0000\n",
      "Epoch 248/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4254 - acc: 0.9130 - val_loss: 0.4918 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.4244 - acc: 0.9130 - val_loss: 0.4906 - val_acc: 1.0000\n",
      "Epoch 250/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4233 - acc: 0.9130 - val_loss: 0.4895 - val_acc: 1.0000\n",
      "Epoch 251/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4223 - acc: 0.9130 - val_loss: 0.4884 - val_acc: 1.0000\n",
      "Epoch 252/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4213 - acc: 0.9130 - val_loss: 0.4872 - val_acc: 1.0000\n",
      "Epoch 253/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4203 - acc: 0.9130 - val_loss: 0.4861 - val_acc: 1.0000\n",
      "Epoch 254/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4192 - acc: 0.9565 - val_loss: 0.4850 - val_acc: 1.0000\n",
      "Epoch 255/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.4182 - acc: 0.9565 - val_loss: 0.4838 - val_acc: 1.0000\n",
      "Epoch 256/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4172 - acc: 0.9565 - val_loss: 0.4827 - val_acc: 1.0000\n",
      "Epoch 257/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4162 - acc: 0.9565 - val_loss: 0.4816 - val_acc: 1.0000\n",
      "Epoch 258/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4152 - acc: 0.9565 - val_loss: 0.4805 - val_acc: 1.0000\n",
      "Epoch 259/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4142 - acc: 0.9565 - val_loss: 0.4794 - val_acc: 1.0000\n",
      "Epoch 260/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.4132 - acc: 1.0000 - val_loss: 0.4783 - val_acc: 1.0000\n",
      "Epoch 261/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4122 - acc: 1.0000 - val_loss: 0.4772 - val_acc: 1.0000\n",
      "Epoch 262/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4112 - acc: 1.0000 - val_loss: 0.4761 - val_acc: 1.0000\n",
      "Epoch 263/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4102 - acc: 1.0000 - val_loss: 0.4750 - val_acc: 1.0000\n",
      "Epoch 264/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4093 - acc: 1.0000 - val_loss: 0.4739 - val_acc: 1.0000\n",
      "Epoch 265/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.4083 - acc: 1.0000 - val_loss: 0.4728 - val_acc: 1.0000\n",
      "Epoch 266/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4073 - acc: 1.0000 - val_loss: 0.4717 - val_acc: 1.0000\n",
      "Epoch 267/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4063 - acc: 1.0000 - val_loss: 0.4706 - val_acc: 1.0000\n",
      "Epoch 268/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4054 - acc: 1.0000 - val_loss: 0.4696 - val_acc: 1.0000\n",
      "Epoch 269/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4044 - acc: 1.0000 - val_loss: 0.4685 - val_acc: 1.0000\n",
      "Epoch 270/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4034 - acc: 1.0000 - val_loss: 0.4674 - val_acc: 1.0000\n",
      "Epoch 271/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4025 - acc: 1.0000 - val_loss: 0.4663 - val_acc: 1.0000\n",
      "Epoch 272/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4015 - acc: 1.0000 - val_loss: 0.4653 - val_acc: 1.0000\n",
      "Epoch 273/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.4005 - acc: 1.0000 - val_loss: 0.4642 - val_acc: 1.0000\n",
      "Epoch 274/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.3996 - acc: 1.0000 - val_loss: 0.4632 - val_acc: 1.0000\n",
      "Epoch 275/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3986 - acc: 1.0000 - val_loss: 0.4621 - val_acc: 1.0000\n",
      "Epoch 276/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3977 - acc: 1.0000 - val_loss: 0.4611 - val_acc: 1.0000\n",
      "Epoch 277/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3968 - acc: 1.0000 - val_loss: 0.4600 - val_acc: 1.0000\n",
      "Epoch 278/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3958 - acc: 1.0000 - val_loss: 0.4590 - val_acc: 1.0000\n",
      "Epoch 279/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.3949 - acc: 1.0000 - val_loss: 0.4579 - val_acc: 1.0000\n",
      "Epoch 280/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3939 - acc: 1.0000 - val_loss: 0.4569 - val_acc: 1.0000\n",
      "Epoch 281/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3930 - acc: 1.0000 - val_loss: 0.4559 - val_acc: 1.0000\n",
      "Epoch 282/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3921 - acc: 1.0000 - val_loss: 0.4548 - val_acc: 1.0000\n",
      "Epoch 283/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3912 - acc: 1.0000 - val_loss: 0.4538 - val_acc: 1.0000\n",
      "Epoch 284/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3902 - acc: 1.0000 - val_loss: 0.4528 - val_acc: 1.0000\n",
      "Epoch 285/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3893 - acc: 1.0000 - val_loss: 0.4518 - val_acc: 1.0000\n",
      "Epoch 286/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3884 - acc: 1.0000 - val_loss: 0.4507 - val_acc: 1.0000\n",
      "Epoch 287/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3875 - acc: 1.0000 - val_loss: 0.4497 - val_acc: 1.0000\n",
      "Epoch 288/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3866 - acc: 1.0000 - val_loss: 0.4487 - val_acc: 1.0000\n",
      "Epoch 289/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3857 - acc: 1.0000 - val_loss: 0.4477 - val_acc: 1.0000\n",
      "Epoch 290/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3848 - acc: 1.0000 - val_loss: 0.4467 - val_acc: 1.0000\n",
      "Epoch 291/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3839 - acc: 1.0000 - val_loss: 0.4457 - val_acc: 1.0000\n",
      "Epoch 292/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3830 - acc: 1.0000 - val_loss: 0.4447 - val_acc: 1.0000\n",
      "Epoch 293/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3821 - acc: 1.0000 - val_loss: 0.4437 - val_acc: 1.0000\n",
      "Epoch 294/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3812 - acc: 1.0000 - val_loss: 0.4427 - val_acc: 1.0000\n",
      "Epoch 295/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3803 - acc: 1.0000 - val_loss: 0.4417 - val_acc: 1.0000\n",
      "Epoch 296/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3794 - acc: 1.0000 - val_loss: 0.4407 - val_acc: 1.0000\n",
      "Epoch 297/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3785 - acc: 1.0000 - val_loss: 0.4397 - val_acc: 1.0000\n",
      "Epoch 298/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3776 - acc: 1.0000 - val_loss: 0.4387 - val_acc: 1.0000\n",
      "Epoch 299/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3767 - acc: 1.0000 - val_loss: 0.4378 - val_acc: 1.0000\n",
      "Epoch 300/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3759 - acc: 1.0000 - val_loss: 0.4368 - val_acc: 1.0000\n",
      "Epoch 301/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.3750 - acc: 1.0000 - val_loss: 0.4358 - val_acc: 1.0000\n",
      "Epoch 302/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3741 - acc: 1.0000 - val_loss: 0.4348 - val_acc: 1.0000\n",
      "Epoch 303/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3732 - acc: 1.0000 - val_loss: 0.4339 - val_acc: 1.0000\n",
      "Epoch 304/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3724 - acc: 1.0000 - val_loss: 0.4329 - val_acc: 1.0000\n",
      "Epoch 305/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3715 - acc: 1.0000 - val_loss: 0.4319 - val_acc: 1.0000\n",
      "Epoch 306/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3707 - acc: 1.0000 - val_loss: 0.4310 - val_acc: 1.0000\n",
      "Epoch 307/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3698 - acc: 1.0000 - val_loss: 0.4300 - val_acc: 1.0000\n",
      "Epoch 308/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3689 - acc: 1.0000 - val_loss: 0.4291 - val_acc: 1.0000\n",
      "Epoch 309/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3681 - acc: 1.0000 - val_loss: 0.4281 - val_acc: 1.0000\n",
      "Epoch 310/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.3673 - acc: 1.0000 - val_loss: 0.4272 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 311/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3664 - acc: 1.0000 - val_loss: 0.4262 - val_acc: 1.0000\n",
      "Epoch 312/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3656 - acc: 1.0000 - val_loss: 0.4253 - val_acc: 1.0000\n",
      "Epoch 313/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3647 - acc: 1.0000 - val_loss: 0.4243 - val_acc: 1.0000\n",
      "Epoch 314/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.3639 - acc: 1.0000 - val_loss: 0.4234 - val_acc: 1.0000\n",
      "Epoch 315/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3630 - acc: 1.0000 - val_loss: 0.4225 - val_acc: 1.0000\n",
      "Epoch 316/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3622 - acc: 1.0000 - val_loss: 0.4215 - val_acc: 1.0000\n",
      "Epoch 317/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3614 - acc: 1.0000 - val_loss: 0.4206 - val_acc: 1.0000\n",
      "Epoch 318/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3606 - acc: 1.0000 - val_loss: 0.4197 - val_acc: 1.0000\n",
      "Epoch 319/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.3597 - acc: 1.0000 - val_loss: 0.4187 - val_acc: 1.0000\n",
      "Epoch 320/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3589 - acc: 1.0000 - val_loss: 0.4178 - val_acc: 1.0000\n",
      "Epoch 321/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3581 - acc: 1.0000 - val_loss: 0.4169 - val_acc: 1.0000\n",
      "Epoch 322/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3573 - acc: 1.0000 - val_loss: 0.4160 - val_acc: 1.0000\n",
      "Epoch 323/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3565 - acc: 1.0000 - val_loss: 0.4151 - val_acc: 1.0000\n",
      "Epoch 324/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3557 - acc: 1.0000 - val_loss: 0.4142 - val_acc: 1.0000\n",
      "Epoch 325/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3549 - acc: 1.0000 - val_loss: 0.4132 - val_acc: 1.0000\n",
      "Epoch 326/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3540 - acc: 1.0000 - val_loss: 0.4123 - val_acc: 1.0000\n",
      "Epoch 327/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3532 - acc: 1.0000 - val_loss: 0.4114 - val_acc: 1.0000\n",
      "Epoch 328/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3524 - acc: 1.0000 - val_loss: 0.4105 - val_acc: 1.0000\n",
      "Epoch 329/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3517 - acc: 1.0000 - val_loss: 0.4096 - val_acc: 1.0000\n",
      "Epoch 330/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3509 - acc: 1.0000 - val_loss: 0.4087 - val_acc: 1.0000\n",
      "Epoch 331/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3501 - acc: 1.0000 - val_loss: 0.4078 - val_acc: 1.0000\n",
      "Epoch 332/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.3493 - acc: 1.0000 - val_loss: 0.4070 - val_acc: 1.0000\n",
      "Epoch 333/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3485 - acc: 1.0000 - val_loss: 0.4061 - val_acc: 1.0000\n",
      "Epoch 334/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3477 - acc: 1.0000 - val_loss: 0.4052 - val_acc: 1.0000\n",
      "Epoch 335/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3469 - acc: 1.0000 - val_loss: 0.4043 - val_acc: 1.0000\n",
      "Epoch 336/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3461 - acc: 1.0000 - val_loss: 0.4034 - val_acc: 1.0000\n",
      "Epoch 337/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3454 - acc: 1.0000 - val_loss: 0.4025 - val_acc: 1.0000\n",
      "Epoch 338/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.3446 - acc: 1.0000 - val_loss: 0.4017 - val_acc: 1.0000\n",
      "Epoch 339/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3438 - acc: 1.0000 - val_loss: 0.4008 - val_acc: 1.0000\n",
      "Epoch 340/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3431 - acc: 1.0000 - val_loss: 0.3999 - val_acc: 1.0000\n",
      "Epoch 341/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3423 - acc: 1.0000 - val_loss: 0.3990 - val_acc: 1.0000\n",
      "Epoch 342/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3415 - acc: 1.0000 - val_loss: 0.3982 - val_acc: 1.0000\n",
      "Epoch 343/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3408 - acc: 1.0000 - val_loss: 0.3973 - val_acc: 1.0000\n",
      "Epoch 344/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.3400 - acc: 1.0000 - val_loss: 0.3965 - val_acc: 1.0000\n",
      "Epoch 345/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3393 - acc: 1.0000 - val_loss: 0.3956 - val_acc: 1.0000\n",
      "Epoch 346/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3385 - acc: 1.0000 - val_loss: 0.3947 - val_acc: 1.0000\n",
      "Epoch 347/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3377 - acc: 1.0000 - val_loss: 0.3939 - val_acc: 1.0000\n",
      "Epoch 348/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3370 - acc: 1.0000 - val_loss: 0.3930 - val_acc: 1.0000\n",
      "Epoch 349/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3363 - acc: 1.0000 - val_loss: 0.3922 - val_acc: 1.0000\n",
      "Epoch 350/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.3355 - acc: 1.0000 - val_loss: 0.3914 - val_acc: 1.0000\n",
      "Epoch 351/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3348 - acc: 1.0000 - val_loss: 0.3905 - val_acc: 1.0000\n",
      "Epoch 352/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3340 - acc: 1.0000 - val_loss: 0.3897 - val_acc: 1.0000\n",
      "Epoch 353/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3333 - acc: 1.0000 - val_loss: 0.3888 - val_acc: 1.0000\n",
      "Epoch 354/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.3326 - acc: 1.0000 - val_loss: 0.3880 - val_acc: 1.0000\n",
      "Epoch 355/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3318 - acc: 1.0000 - val_loss: 0.3872 - val_acc: 1.0000\n",
      "Epoch 356/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3311 - acc: 1.0000 - val_loss: 0.3863 - val_acc: 1.0000\n",
      "Epoch 357/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3304 - acc: 1.0000 - val_loss: 0.3855 - val_acc: 1.0000\n",
      "Epoch 358/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3296 - acc: 1.0000 - val_loss: 0.3847 - val_acc: 1.0000\n",
      "Epoch 359/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3289 - acc: 1.0000 - val_loss: 0.3839 - val_acc: 1.0000\n",
      "Epoch 360/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3282 - acc: 1.0000 - val_loss: 0.3830 - val_acc: 1.0000\n",
      "Epoch 361/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3275 - acc: 1.0000 - val_loss: 0.3822 - val_acc: 1.0000\n",
      "Epoch 362/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3268 - acc: 1.0000 - val_loss: 0.3814 - val_acc: 1.0000\n",
      "Epoch 363/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.3261 - acc: 1.0000 - val_loss: 0.3806 - val_acc: 1.0000\n",
      "Epoch 364/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3254 - acc: 1.0000 - val_loss: 0.3798 - val_acc: 1.0000\n",
      "Epoch 365/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3246 - acc: 1.0000 - val_loss: 0.3790 - val_acc: 1.0000\n",
      "Epoch 366/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3239 - acc: 1.0000 - val_loss: 0.3782 - val_acc: 1.0000\n",
      "Epoch 367/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3232 - acc: 1.0000 - val_loss: 0.3774 - val_acc: 1.0000\n",
      "Epoch 368/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3225 - acc: 1.0000 - val_loss: 0.3766 - val_acc: 1.0000\n",
      "Epoch 369/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.3218 - acc: 1.0000 - val_loss: 0.3758 - val_acc: 1.0000\n",
      "Epoch 370/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3211 - acc: 1.0000 - val_loss: 0.3750 - val_acc: 1.0000\n",
      "Epoch 371/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3204 - acc: 1.0000 - val_loss: 0.3742 - val_acc: 1.0000\n",
      "Epoch 372/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3198 - acc: 1.0000 - val_loss: 0.3734 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 373/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3191 - acc: 1.0000 - val_loss: 0.3726 - val_acc: 1.0000\n",
      "Epoch 374/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3184 - acc: 1.0000 - val_loss: 0.3718 - val_acc: 1.0000\n",
      "Epoch 375/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.3177 - acc: 1.0000 - val_loss: 0.3710 - val_acc: 1.0000\n",
      "Epoch 376/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3170 - acc: 1.0000 - val_loss: 0.3702 - val_acc: 1.0000\n",
      "Epoch 377/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3163 - acc: 1.0000 - val_loss: 0.3695 - val_acc: 1.0000\n",
      "Epoch 378/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3157 - acc: 1.0000 - val_loss: 0.3687 - val_acc: 1.0000\n",
      "Epoch 379/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3150 - acc: 1.0000 - val_loss: 0.3679 - val_acc: 1.0000\n",
      "Epoch 380/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3143 - acc: 1.0000 - val_loss: 0.3671 - val_acc: 1.0000\n",
      "Epoch 381/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.3136 - acc: 1.0000 - val_loss: 0.3664 - val_acc: 1.0000\n",
      "Epoch 382/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3130 - acc: 1.0000 - val_loss: 0.3656 - val_acc: 1.0000\n",
      "Epoch 383/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3123 - acc: 1.0000 - val_loss: 0.3648 - val_acc: 1.0000\n",
      "Epoch 384/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3116 - acc: 1.0000 - val_loss: 0.3641 - val_acc: 1.0000\n",
      "Epoch 385/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3110 - acc: 1.0000 - val_loss: 0.3633 - val_acc: 1.0000\n",
      "Epoch 386/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3103 - acc: 1.0000 - val_loss: 0.3625 - val_acc: 1.0000\n",
      "Epoch 387/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3097 - acc: 1.0000 - val_loss: 0.3618 - val_acc: 1.0000\n",
      "Epoch 388/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3090 - acc: 1.0000 - val_loss: 0.3610 - val_acc: 1.0000\n",
      "Epoch 389/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3083 - acc: 1.0000 - val_loss: 0.3603 - val_acc: 1.0000\n",
      "Epoch 390/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3077 - acc: 1.0000 - val_loss: 0.3595 - val_acc: 1.0000\n",
      "Epoch 391/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3070 - acc: 1.0000 - val_loss: 0.3588 - val_acc: 1.0000\n",
      "Epoch 392/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3064 - acc: 1.0000 - val_loss: 0.3580 - val_acc: 1.0000\n",
      "Epoch 393/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3058 - acc: 1.0000 - val_loss: 0.3573 - val_acc: 1.0000\n",
      "Epoch 394/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3051 - acc: 1.0000 - val_loss: 0.3565 - val_acc: 1.0000\n",
      "Epoch 395/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3045 - acc: 1.0000 - val_loss: 0.3558 - val_acc: 1.0000\n",
      "Epoch 396/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3038 - acc: 1.0000 - val_loss: 0.3551 - val_acc: 1.0000\n",
      "Epoch 397/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3032 - acc: 1.0000 - val_loss: 0.3543 - val_acc: 1.0000\n",
      "Epoch 398/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3026 - acc: 1.0000 - val_loss: 0.3536 - val_acc: 1.0000\n",
      "Epoch 399/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3019 - acc: 1.0000 - val_loss: 0.3529 - val_acc: 1.0000\n",
      "Epoch 400/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3013 - acc: 1.0000 - val_loss: 0.3521 - val_acc: 1.0000\n",
      "Epoch 401/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3007 - acc: 1.0000 - val_loss: 0.3514 - val_acc: 1.0000\n",
      "Epoch 402/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.3000 - acc: 1.0000 - val_loss: 0.3507 - val_acc: 1.0000\n",
      "Epoch 403/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2994 - acc: 1.0000 - val_loss: 0.3500 - val_acc: 1.0000\n",
      "Epoch 404/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2988 - acc: 1.0000 - val_loss: 0.3492 - val_acc: 1.0000\n",
      "Epoch 405/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2982 - acc: 1.0000 - val_loss: 0.3485 - val_acc: 1.0000\n",
      "Epoch 406/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2975 - acc: 1.0000 - val_loss: 0.3478 - val_acc: 1.0000\n",
      "Epoch 407/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2969 - acc: 1.0000 - val_loss: 0.3471 - val_acc: 1.0000\n",
      "Epoch 408/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2963 - acc: 1.0000 - val_loss: 0.3464 - val_acc: 1.0000\n",
      "Epoch 409/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2957 - acc: 1.0000 - val_loss: 0.3457 - val_acc: 1.0000\n",
      "Epoch 410/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2951 - acc: 1.0000 - val_loss: 0.3450 - val_acc: 1.0000\n",
      "Epoch 411/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2945 - acc: 1.0000 - val_loss: 0.3443 - val_acc: 1.0000\n",
      "Epoch 412/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2939 - acc: 1.0000 - val_loss: 0.3436 - val_acc: 1.0000\n",
      "Epoch 413/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2933 - acc: 1.0000 - val_loss: 0.3429 - val_acc: 1.0000\n",
      "Epoch 414/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2927 - acc: 1.0000 - val_loss: 0.3422 - val_acc: 1.0000\n",
      "Epoch 415/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2921 - acc: 1.0000 - val_loss: 0.3415 - val_acc: 1.0000\n",
      "Epoch 416/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2915 - acc: 1.0000 - val_loss: 0.3408 - val_acc: 1.0000\n",
      "Epoch 417/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2909 - acc: 1.0000 - val_loss: 0.3401 - val_acc: 1.0000\n",
      "Epoch 418/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2903 - acc: 1.0000 - val_loss: 0.3394 - val_acc: 1.0000\n",
      "Epoch 419/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2897 - acc: 1.0000 - val_loss: 0.3387 - val_acc: 1.0000\n",
      "Epoch 420/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2891 - acc: 1.0000 - val_loss: 0.3380 - val_acc: 1.0000\n",
      "Epoch 421/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2885 - acc: 1.0000 - val_loss: 0.3373 - val_acc: 1.0000\n",
      "Epoch 422/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2879 - acc: 1.0000 - val_loss: 0.3366 - val_acc: 1.0000\n",
      "Epoch 423/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2873 - acc: 1.0000 - val_loss: 0.3360 - val_acc: 1.0000\n",
      "Epoch 424/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2867 - acc: 1.0000 - val_loss: 0.3353 - val_acc: 1.0000\n",
      "Epoch 425/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2862 - acc: 1.0000 - val_loss: 0.3346 - val_acc: 1.0000\n",
      "Epoch 426/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2856 - acc: 1.0000 - val_loss: 0.3339 - val_acc: 1.0000\n",
      "Epoch 427/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2850 - acc: 1.0000 - val_loss: 0.3333 - val_acc: 1.0000\n",
      "Epoch 428/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2844 - acc: 1.0000 - val_loss: 0.3326 - val_acc: 1.0000\n",
      "Epoch 429/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2839 - acc: 1.0000 - val_loss: 0.3319 - val_acc: 1.0000\n",
      "Epoch 430/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2833 - acc: 1.0000 - val_loss: 0.3313 - val_acc: 1.0000\n",
      "Epoch 431/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2827 - acc: 1.0000 - val_loss: 0.3306 - val_acc: 1.0000\n",
      "Epoch 432/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2821 - acc: 1.0000 - val_loss: 0.3299 - val_acc: 1.0000\n",
      "Epoch 433/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2816 - acc: 1.0000 - val_loss: 0.3293 - val_acc: 1.0000\n",
      "Epoch 434/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2810 - acc: 1.0000 - val_loss: 0.3286 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 435/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2804 - acc: 1.0000 - val_loss: 0.3280 - val_acc: 1.0000\n",
      "Epoch 436/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2799 - acc: 1.0000 - val_loss: 0.3273 - val_acc: 1.0000\n",
      "Epoch 437/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2793 - acc: 1.0000 - val_loss: 0.3267 - val_acc: 1.0000\n",
      "Epoch 438/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2788 - acc: 1.0000 - val_loss: 0.3260 - val_acc: 1.0000\n",
      "Epoch 439/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2782 - acc: 1.0000 - val_loss: 0.3254 - val_acc: 1.0000\n",
      "Epoch 440/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2777 - acc: 1.0000 - val_loss: 0.3247 - val_acc: 1.0000\n",
      "Epoch 441/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2771 - acc: 1.0000 - val_loss: 0.3241 - val_acc: 1.0000\n",
      "Epoch 442/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2766 - acc: 1.0000 - val_loss: 0.3234 - val_acc: 1.0000\n",
      "Epoch 443/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2760 - acc: 1.0000 - val_loss: 0.3228 - val_acc: 1.0000\n",
      "Epoch 444/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2755 - acc: 1.0000 - val_loss: 0.3221 - val_acc: 1.0000\n",
      "Epoch 445/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2749 - acc: 1.0000 - val_loss: 0.3215 - val_acc: 1.0000\n",
      "Epoch 446/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2744 - acc: 1.0000 - val_loss: 0.3209 - val_acc: 1.0000\n",
      "Epoch 447/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2738 - acc: 1.0000 - val_loss: 0.3202 - val_acc: 1.0000\n",
      "Epoch 448/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2733 - acc: 1.0000 - val_loss: 0.3196 - val_acc: 1.0000\n",
      "Epoch 449/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2727 - acc: 1.0000 - val_loss: 0.3190 - val_acc: 1.0000\n",
      "Epoch 450/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2722 - acc: 1.0000 - val_loss: 0.3183 - val_acc: 1.0000\n",
      "Epoch 451/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2717 - acc: 1.0000 - val_loss: 0.3177 - val_acc: 1.0000\n",
      "Epoch 452/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2711 - acc: 1.0000 - val_loss: 0.3171 - val_acc: 1.0000\n",
      "Epoch 453/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2706 - acc: 1.0000 - val_loss: 0.3165 - val_acc: 1.0000\n",
      "Epoch 454/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2701 - acc: 1.0000 - val_loss: 0.3159 - val_acc: 1.0000\n",
      "Epoch 455/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2695 - acc: 1.0000 - val_loss: 0.3152 - val_acc: 1.0000\n",
      "Epoch 456/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2690 - acc: 1.0000 - val_loss: 0.3146 - val_acc: 1.0000\n",
      "Epoch 457/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2685 - acc: 1.0000 - val_loss: 0.3140 - val_acc: 1.0000\n",
      "Epoch 458/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2680 - acc: 1.0000 - val_loss: 0.3134 - val_acc: 1.0000\n",
      "Epoch 459/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2674 - acc: 1.0000 - val_loss: 0.3128 - val_acc: 1.0000\n",
      "Epoch 460/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2669 - acc: 1.0000 - val_loss: 0.3122 - val_acc: 1.0000\n",
      "Epoch 461/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2664 - acc: 1.0000 - val_loss: 0.3116 - val_acc: 1.0000\n",
      "Epoch 462/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2659 - acc: 1.0000 - val_loss: 0.3110 - val_acc: 1.0000\n",
      "Epoch 463/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2654 - acc: 1.0000 - val_loss: 0.3104 - val_acc: 1.0000\n",
      "Epoch 464/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2649 - acc: 1.0000 - val_loss: 0.3098 - val_acc: 1.0000\n",
      "Epoch 465/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2643 - acc: 1.0000 - val_loss: 0.3092 - val_acc: 1.0000\n",
      "Epoch 466/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2638 - acc: 1.0000 - val_loss: 0.3086 - val_acc: 1.0000\n",
      "Epoch 467/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2633 - acc: 1.0000 - val_loss: 0.3080 - val_acc: 1.0000\n",
      "Epoch 468/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2628 - acc: 1.0000 - val_loss: 0.3074 - val_acc: 1.0000\n",
      "Epoch 469/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2623 - acc: 1.0000 - val_loss: 0.3068 - val_acc: 1.0000\n",
      "Epoch 470/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2618 - acc: 1.0000 - val_loss: 0.3062 - val_acc: 1.0000\n",
      "Epoch 471/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2613 - acc: 1.0000 - val_loss: 0.3056 - val_acc: 1.0000\n",
      "Epoch 472/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2608 - acc: 1.0000 - val_loss: 0.3050 - val_acc: 1.0000\n",
      "Epoch 473/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2603 - acc: 1.0000 - val_loss: 0.3044 - val_acc: 1.0000\n",
      "Epoch 474/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2598 - acc: 1.0000 - val_loss: 0.3038 - val_acc: 1.0000\n",
      "Epoch 475/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2593 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 1.0000\n",
      "Epoch 476/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2588 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 1.0000\n",
      "Epoch 477/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2583 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 1.0000\n",
      "Epoch 478/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2578 - acc: 1.0000 - val_loss: 0.3015 - val_acc: 1.0000\n",
      "Epoch 479/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2573 - acc: 1.0000 - val_loss: 0.3009 - val_acc: 1.0000\n",
      "Epoch 480/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2568 - acc: 1.0000 - val_loss: 0.3004 - val_acc: 1.0000\n",
      "Epoch 481/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2563 - acc: 1.0000 - val_loss: 0.2998 - val_acc: 1.0000\n",
      "Epoch 482/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2559 - acc: 1.0000 - val_loss: 0.2992 - val_acc: 1.0000\n",
      "Epoch 483/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2554 - acc: 1.0000 - val_loss: 0.2987 - val_acc: 1.0000\n",
      "Epoch 484/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2549 - acc: 1.0000 - val_loss: 0.2981 - val_acc: 1.0000\n",
      "Epoch 485/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2544 - acc: 1.0000 - val_loss: 0.2975 - val_acc: 1.0000\n",
      "Epoch 486/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2539 - acc: 1.0000 - val_loss: 0.2970 - val_acc: 1.0000\n",
      "Epoch 487/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2534 - acc: 1.0000 - val_loss: 0.2964 - val_acc: 1.0000\n",
      "Epoch 488/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2530 - acc: 1.0000 - val_loss: 0.2958 - val_acc: 1.0000\n",
      "Epoch 489/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2525 - acc: 1.0000 - val_loss: 0.2953 - val_acc: 1.0000\n",
      "Epoch 490/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2520 - acc: 1.0000 - val_loss: 0.2947 - val_acc: 1.0000\n",
      "Epoch 491/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2515 - acc: 1.0000 - val_loss: 0.2942 - val_acc: 1.0000\n",
      "Epoch 492/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2511 - acc: 1.0000 - val_loss: 0.2936 - val_acc: 1.0000\n",
      "Epoch 493/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2506 - acc: 1.0000 - val_loss: 0.2931 - val_acc: 1.0000\n",
      "Epoch 494/500\n",
      "23/23 [==============================] - 0s 679us/step - loss: 0.2501 - acc: 1.0000 - val_loss: 0.2925 - val_acc: 1.0000\n",
      "Epoch 495/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2497 - acc: 1.0000 - val_loss: 0.2920 - val_acc: 1.0000\n",
      "Epoch 496/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2492 - acc: 1.0000 - val_loss: 0.2914 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2487 - acc: 1.0000 - val_loss: 0.2909 - val_acc: 1.0000\n",
      "Epoch 498/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2483 - acc: 1.0000 - val_loss: 0.2903 - val_acc: 1.0000\n",
      "Epoch 499/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2478 - acc: 1.0000 - val_loss: 0.2898 - val_acc: 1.0000\n",
      "Epoch 500/500\n",
      "23/23 [==============================] - 0s 0us/step - loss: 0.2473 - acc: 1.0000 - val_loss: 0.2892 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae181299e8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_input,labels, batch_size=128, epochs=500, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(np.asarray([[17.50,17.50]]))\n",
    "if predict[0][0]>predict[0][1]:\n",
    "    print(\"Red\")\n",
    "else:\n",
    "    print(\"Blue\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
